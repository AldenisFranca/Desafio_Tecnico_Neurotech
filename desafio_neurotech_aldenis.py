# -*- coding: utf-8 -*-
"""Desafio_NeuroTech_Aldenis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16LZH2CZCyoanQhPm-Z4FcrWb4tfUM_Y7

#Case - Engenharia de Dados - NEUROTECH

###Candidato: Aldenis Everton Alves Guilherme de França

###Importação de Bibliotecas
"""

# Bibliotecas para modelagem de dados
import pandas as pd
import numpy as np
import glob

# Bibliotecas para análises gráficas
import matplotlib.pyplot as plt
import seaborn as sns

# Bibliotecas/classes para tratamento dos dados categóricos
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

# Bibliotecas/classes para normalização dos dados
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import Normalizer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler

"""###Importação da Base de Dados"""

# Leitura e concatenação das 648 planilhas da base de dados.

path = r'drive/MyDrive/Desafio_NeuroTech'
files_cons = glob.glob(path + '/*CONS.csv')
files_det = glob.glob(path + '/*DET.csv')

list_cons = []
list_det = []

for i in files_cons:
  dataset_cons = pd.read_csv(i, sep=',', header=0, encoding='ISO-8859-1')
  list_cons.append(dataset_cons)

for j in files_det:
  dataset_det = pd.read_csv(j, sep=',', header=0, encoding='ISO-8859-1')
  list_det.append(dataset_det)

df_cons = pd.concat(list_cons, axis=0, ignore_index=True)
df_det = pd.concat(list_det, axis=0, ignore_index=True)

"""###Construção da Tabela Única"""

# Integração dos dados das tabelas CONS e DET.
df_completo = pd.merge(df_det, df_cons, how='outer', on=['#ID_EVENTO','UF_PRESTADOR','LG_OUTLIER'])

"""###Análise Exploratória dos Dados

#####Dimensão dos Dados
"""

# Especificação do número de linhas e colunas da tabela consolidada.
print(f'QUANTIDADE DE LINHAS: {df_completo.shape[0]}\n')
print(f'QUANTIDADE DE COLUNAS: {df_completo.shape[1]}')

"""#####Apresentação dos Dados"""

# Visualização parcial da tabela consolidada.
df_completo.head()

# Nomes das colunas da base consolidada.
df_completo.columns

"""#####Informações Estatísticas dos Dados"""

# Métricas estatísticas da tabela CONS.
df_cons.describe(include='all')

# Métricas estatísticas da tabela DET.
df_det.describe(include='all')

# Quantidade de dados nulos em cada coluna da base consolidada.
df_completo.isnull().sum()

# Porcentagem de dados nulos em relação ao total 
# de cada coluna da base consolidada.
(df_completo.isna().mean())*100

# Tipos de variáveis de cada coluna da base consolidada.
df_completo.info()

# Agrupamento de Dados por classes.

print("AGRUPAMENTO de alguns dados por classes:\n")

print('MÉDIA - Sexo x Idade:')
med_sexo_idade = df_completo.groupby('SEXO_BENEFICIARIO')['IDADE_BENEFICIARIO'].mean()
print(f'{med_sexo_idade}\n')

print('MEDIANA - Sexo x Idade:')
mdn_sexo_idade = df_completo.groupby('SEXO_BENEFICIARIO')['IDADE_BENEFICIARIO'].median()
print(f'{mdn_sexo_idade}\n')

print('O item faz parte de um Pacote de Procedimentos? (0: Não, 1: Sim)')
print(df_completo.groupby('LG_PACOTE').size())
print('')

print(df_completo.groupby('PORTE_OPERADORA').size())
print('')

print('CÓDIGO DO PROCEDIMENTO PELA TUSS')
print(df_completo.groupby('CD_TUSS_PROCEDIMENTO').size().sort_values())
print('')

print(df_completo.groupby('SEXO_BENEFICIARIO').size())
print('')

print(df_completo.groupby('CARATER_ATENDIMENTO').size())
print('')

print(df_completo.groupby('LG_OUTLIER').size())
print('')

print('MÉDIA - UF x Idade:')
med_uf_idade = df_completo.groupby('UF_PRESTADOR')['IDADE_BENEFICIARIO'].mean().sort_values()
print(f'{med_uf_idade}\n')

df_completo.groupby('QT_PROCEDIMENTO')['LG_OUTLIER'].size().sort_values()

"""#####Análise Gráfica"""

#Construção dos gráficos boxplot de cada classe.

colunas = ['#ID_EVENTO','QT_PROCEDIMENTO','VL_PROCEDIMENTO','VL_PAGO_FORNECEDOR',
           'CD_TABELA_REFERENCIA','LG_PACOTE','IND_TABELA_PROPRIA','LG_OUTLIER',
           'ID_PLANO', 'IDADE_BENEFICIARIO','CD_MUNIC_BENEFICIARIO','CD_MODALIDADE_OPERADORA',
        'CD_MUNIC_PRESTADOR','TIPO_INTERNACAO','REGIME_INTERNACAO', 'MOTIVO_ENCERRAMENTO',
        'NR_DIARIAS_ACOMPANHANTE', 'NR_DIARIAS_UTI','LG_VALOR_PREESTABELECIDO']
#A lista colunas refere-se somente às colunas de valores numéricos do df_completo.

print('BOXPLOT dos dados de cada classe:\n')
for k in range(0,len(colunas)):
  df_completo[colunas[k]].plot(kind='box', subplots=True, layout=(8,4), sharex=False, sharey=False, figsize=(18,18))
  plt.show()

#Construção dos gráficos de histograma de cada classe.

print("HISTOGRAMAS dos dados de cada classe:\n")
df_completo.hist(layout=(5,4),figsize=(20,20))
plt.savefig('histogramas.jpg',dpi=200)

#Construção da matriz de correlação entre as classes do df_cons.

print('Matriz de Correlação - HEATMAP do df_cons:\n')
plt.figure(figsize=(15,15))
ax = sns.heatmap(df_cons.corr(), cmap='Blues', annot=True)
plt.savefig('heatmap_cons.jpg',dpi=200)

#Construção da matriz de correlação entre as classes do df_det.

print('Matriz de Correlação - HEATMAP no df_det:\n')
plt.figure(figsize=(12,12))
ax=sns.heatmap(df_det.corr(), cmap='Blues', annot=True)
plt.savefig('heatmap_det.jpg',dpi=200)

"""###Pré-processamento dos Dados

#####Criação de Novas Features
"""

# Quantidade de dias de internação.

d1 = pd.to_datetime(df_completo['DT_SAIDA_INTERNACAO'],dayfirst=True)
d2 = pd.to_datetime(df_completo['DT_INTERNACAO'],dayfirst=True)
df_completo['DIAS_INTERNACAO'] = abs((d2-d1)).astype('timedelta64[D]')

# Quantidade de recorrência de diagnósticos.

df_completo['CID_1_bool'] = np.where(df_completo['CID_1'].isna(), 0, 1)
df_completo['CID_2_bool'] = np.where(df_completo['CID_2'].isna(), 0, 1)
df_completo['CID_3_bool'] = np.where(df_completo['CID_3'].isna(), 0, 1)
df_completo['CID_4_bool'] = np.where(df_completo['CID_4'].isna(), 0, 1)

df_completo['QTD_DIAGNOSTICOS'] = df_completo['CID_1_bool']+df_completo['CID_2_bool']+df_completo['CID_3_bool']+df_completo['CID_4_bool']

"""#####Remoção de colunas"""

# Remoção de algumas colunas da tabela consolidada.

del df_completo['DT_INICIO_EVENTO']
del df_completo['MODALIDADE_OPERADORA']
del df_completo['CID_2']
del df_completo['CID_3']
del df_completo['CID_4']
del df_completo['CID_1_bool']
del df_completo['CID_2_bool']
del df_completo['CID_3_bool']
del df_completo['CID_4_bool']
del df_completo['DT_INTERNACAO']
del df_completo['DT_SAIDA_INTERNACAO']

# Visualização da Tabela Filtrada, após a remoção de algumas colunas.

df_completo_filt = df_completo
df_completo_filt

"""#####Tratamento dos Dados Nulos"""

# Dados estatísticos da feature nova.

df_completo_filt['DIAS_INTERNACAO'].describe()

# Substituindo os valores nulos pela mediana ou pela média ou pela moda ou por -1 ou por uma string.

col_null = [['QT_PROCEDIMENTO','VL_PROCEDIMENTO','LG_PACOTE','IND_TABELA_PROPRIA','IDADE_BENEFICIARIO','NR_DIARIAS_UTI','NR_DIARIAS_ACOMPANHANTE'],
            ['VL_PAGO_FORNECEDOR'],
            ['TIPO_INTERNACAO','REGIME_INTERNACAO','MOTIVO_ENCERRAMENTO','CD_TABELA_REFERENCIA','DIAS_INTERNACAO','LG_VALOR_PREESTABELECIDO','CD_TUSS_PROCEDIMENTO'],
            ['CD_MUNIC_PRESTADOR', 'CD_MUNIC_BENEFICIARIO','CD_MODALIDADE_OPERADORA', 'ID_PLANO', 'SEXO_BENEFICIARIO', 'CID_1', 'CARATER_ATENDIMENTO'],
            ['PORTE_OPERADORA']]

for col in col_null[0]:
  df_completo_filt[col].fillna(df_completo_filt[col].median(),inplace=True)

for col in col_null[1]:
  df_completo_filt[col].fillna(df_completo_filt[col].mean(),inplace=True)

for col in col_null[2]:
  df_completo_filt[col].fillna(df_completo_filt[col].mode()[0],inplace=True)

for col in col_null[3]:
  df_completo_filt[col].fillna(-1,inplace=True)

for col in col_null[4]:
  df_completo_filt[col].fillna('SEM BENEFICIARIOS',inplace=True)

# Quantidade de valores nulos por coluna da base filtrada após o tratamento.

df_completo_filt.isnull().sum()

"""#####Conversão dos Dados Categóricos em Numéricos"""

# Substituição dos códigos strings do caráter de atendimento pelos códigos
# numéricos, de acordo com tabela 23 da TUSS.

str_atend = ['E','U','1','2']
int_atend = [1,2,1,2]

df_completo_filt['CARATER_ATENDIMENTO'].replace(str_atend,int_atend,inplace=True)

# Conversão dos dados das colunas SEXO_BENEFICIARIO e CID_1 em strings.

df_completo_filt['CARATER_ATENDIMENTO'] = df_completo_filt['CARATER_ATENDIMENTO'].astype(str)
df_completo_filt['SEXO_BENEFICIARIO'] = df_completo_filt['SEXO_BENEFICIARIO'].astype(str)
df_completo_filt['CID_1'] = df_completo_filt['CID_1'].astype(str)

# Aplicação da classe LabelEncoder a algumas colunas.

col_object = ['UF_PRESTADOR','CD_TUSS_PROCEDIMENTO','PORTE_OPERADORA','CID_1','SEXO_BENEFICIARIO','CARATER_ATENDIMENTO']

le = LabelEncoder()
for col in col_object:
  df_completo_filt[col] = le.fit_transform(df_completo_filt[col])

# Aplicação da classe One-Hot-Encoder às classes PORTE_OPERADORA e SEXO_BENEFICIARIO.

onehotencoder = OneHotEncoder()
K = onehotencoder.fit_transform(df_completo_filt.PORTE_OPERADORA.values.reshape(-1,1)).toarray()
W = onehotencoder.fit_transform(df_completo_filt.SEXO_BENEFICIARIO.values.reshape(-1,1)).toarray()
Z = onehotencoder.fit_transform(df_completo_filt.CARATER_ATENDIMENTO.values.reshape(-1,1)).toarray()

# Conversão dos arrays K e W OneHot para um Dataframe cada e adição das colunas desses 
# Dataframes (dfOneHot1 e dfOneHot2) ao nosso Dataframe filtrado (df_completo_filt).

dfOneHot1 = pd.DataFrame(K, columns= ['PORTE_OPER_'+str(int(i)) for i in range(K.shape[1])])
dfOneHot2 = pd.DataFrame(W, columns= ['SEXO_'+str(int(i)) for i in range(W.shape[1])])
dfOneHot3 = pd.DataFrame(Z, columns= ['ATEND_'+str(int(i)) for i in range(Z.shape[1])])

df_completo_filt['PORTE_GRANDE'] = dfOneHot1['PORTE_OPER_0']
df_completo_filt['PORTE_MEDIO'] = dfOneHot1['PORTE_OPER_1']
df_completo_filt['PORTE_PEQUENO'] = dfOneHot1['PORTE_OPER_2']
df_completo_filt['SEM_BENEFICIARIOS'] = dfOneHot1['PORTE_OPER_3']

df_completo_filt['SEXO_F'] = dfOneHot2['SEXO_1']
df_completo_filt['SEXO_M'] = dfOneHot2['SEXO_2']
df_completo_filt['SEXO_NAO_INFOR'] = dfOneHot2['SEXO_0']

df_completo_filt['ATEND_ELETIVO'] = dfOneHot3['ATEND_1']
df_completo_filt['ATEND_URGENCIA'] = dfOneHot3['ATEND_2']
df_completo_filt['ATEND_NAO_INFOR'] = dfOneHot3['ATEND_0']

del df_completo_filt['PORTE_OPERADORA']
del df_completo_filt['SEXO_BENEFICIARIO']
del df_completo_filt['CARATER_ATENDIMENTO']

print(df_completo_filt.shape)
df_completo_filt.head()

df_completo_filt.info()

"""#####Normalização dos Dados"""

# Uso de fórmulas matemáticas para calcular a normalização, usando a amplitude dos dados.
# Método semelhante é usado na classe MinMaxScaler do sklearn.

X=[]

for t in df_completo_filt.columns:
  Min = df_completo_filt[t].min()
  Max = df_completo_filt[t].max()
  Ampl = Max-Min
  if Ampl == 0:
    Ampl = 1
  array = ((df_completo_filt[t].values) - Min) / Ampl
  X.append(array)

np.set_printoptions(precision=3)
print(X)

# Uso de fórmulas matemáticas para calcular a normalização, usando a distância interquartil.
# Método semelhante é usado na classe RobustScaler do sklearn.

X=[]

for t in df_completo_filt.columns:
  Q1 = df_completo_filt[t].quantile(0.25)
  Q3 = df_completo_filt[t].quantile(0.75)
  IQR = Q3 - Q1 # intervalo interquartílico
  if IQR == 0:
    IQR = 1
  array = ((df_completo_filt[t].values) - Q1) / IQR
  X.append(array)

np.set_printoptions(precision=3)
print(X)

# Normalização dos dados utilizando-se a classe Normalizer do sklearn.

# obtendo os valores do dataset
X = df_completo_filt.values

# normaliza os dados
scaler = Normalizer() 
normalizedX = scaler.fit_transform(X)

print('DADOS NORMALIZADOS\n')
np.set_printoptions(precision=3)
print(normalizedX)

# Para os demais casos, basta substituir scaler = Normalizer() por
# scaler = RobustScaler() ou StandardScaler() ou MinMaxScaler().